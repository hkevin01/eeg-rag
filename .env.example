# ============================================================================
# EEG-RAG Configuration
# ============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# See INSTALL.md for detailed configuration instructions.
# ============================================================================

# ----------------------------------------------------------------------------
# LLM Configuration (Required for generation features)
# ----------------------------------------------------------------------------

# OpenAI API Key - Get from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# Model selection (optional, defaults shown)
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ----------------------------------------------------------------------------
# PubMed API (Recommended)
# ----------------------------------------------------------------------------

# Email for PubMed E-utilities (required for higher rate limits)
PUBMED_EMAIL=your-email@example.com

# Optional: NCBI API key for even higher limits
# NCBI_API_KEY=your-ncbi-api-key

# ----------------------------------------------------------------------------
# Knowledge Graph - Neo4j (Optional)
# ----------------------------------------------------------------------------

# Uncomment to enable Neo4j knowledge graph features
# NEO4J_URI=bolt://localhost:7687
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=your-secure-password

# ----------------------------------------------------------------------------
# Caching - Redis (Optional)
# ----------------------------------------------------------------------------

# Uncomment to enable Redis caching
# REDIS_URL=redis://localhost:6379
# REDIS_PASSWORD=

# Cache TTL in seconds (default: 3600 = 1 hour)
# CACHE_TTL=3600

# ----------------------------------------------------------------------------
# Embedding Configuration
# ----------------------------------------------------------------------------

# Local embedding model (sentence-transformers)
# Default: all-mpnet-base-v2 (best quality)
# Alternative: all-MiniLM-L6-v2 (faster, smaller)
# EEG_RAG_EMBEDDING_MODEL=all-mpnet-base-v2

# Embedding cache directory
# EMBEDDING_CACHE_DIR=data/embeddings/cache

# ----------------------------------------------------------------------------
# Retrieval Configuration
# ----------------------------------------------------------------------------

# Number of documents to retrieve
# TOP_K_DOCUMENTS=10

# Hybrid search weight (0=BM25 only, 1=dense only, 0.5=balanced)
# HYBRID_ALPHA=0.5

# ----------------------------------------------------------------------------
# Logging Configuration
# ----------------------------------------------------------------------------

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (optional)
# LOG_FILE=logs/eeg_rag.log

# ----------------------------------------------------------------------------
# Performance Tuning
# ----------------------------------------------------------------------------

# Maximum concurrent requests
# MAX_CONCURRENT_REQUESTS=10

# Request timeout in seconds
# REQUEST_TIMEOUT=30

# Batch size for processing
# BATCH_SIZE=32
