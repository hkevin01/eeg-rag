# Agentic RAG Architecture for EEG Research

**Document Version**: 1.0  
**Date**: November 21, 2025  
**Status**: ğŸŸ¡ In Development

---

## ğŸ¯ Overview

This document describes the **Multi-Agent RAG Architecture** for EEG research, implementing a sophisticated orchestration system with multiple specialized agents, query planning, Chain-of-Thought (CoT) reasoning, and ReAct patterns.

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER QUERY INPUT                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR AGENT                            â”‚
â”‚  â€¢ Query Understanding                                           â”‚
â”‚  â€¢ Query Planning (ReAct)                                        â”‚
â”‚  â€¢ Chain-of-Thought (CoT) Reasoning                             â”‚
â”‚  â€¢ Task Decomposition                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
        â”‚                  â”‚                  â”‚                â”‚
        â”‚                  â”‚                  â”‚                â”‚
        â–¼                  â–¼                  â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 1    â”‚   â”‚  AGENT 2    â”‚   â”‚  AGENT 3    â”‚   â”‚  AGENT 4     â”‚
â”‚  Local Data â”‚   â”‚  Web Search â”‚   â”‚  Cloud KB   â”‚   â”‚  MCP Server  â”‚
â”‚  Sources    â”‚   â”‚  Engine     â”‚   â”‚  (AWS/Azure)â”‚   â”‚  Integration â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚                 â”‚
       â”‚                 â”‚                 â”‚                 â”‚
       â–¼                 â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTEXT AGGREGATOR                            â”‚
â”‚  â€¢ Short-term Memory (Working Context)                           â”‚
â”‚  â€¢ Long-term Memory (Persistent Knowledge)                       â”‚
â”‚  â€¢ Context Fusion & Deduplication                               â”‚
â”‚  â€¢ Relevance Scoring                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENERATION ENSEMBLE                           â”‚
â”‚  â€¢ GPT-4 (OpenAI)                                               â”‚
â”‚  â€¢ Gemini (Google)                                              â”‚
â”‚  â€¢ Claude (Anthropic)                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGGREGATOR AGENT                              â”‚
â”‚  â€¢ Response Synthesis                                            â”‚
â”‚  â€¢ Citation Consolidation                                        â”‚
â”‚  â€¢ Confidence Scoring                                            â”‚
â”‚  â€¢ Quality Assurance                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FINAL RESPONSE TO USER                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Agent Specifications

### Orchestrator Agent
**Role**: Query understanding, planning, and coordination  
**Techniques**: ReAct, Chain-of-Thought (CoT), Task Decomposition

**Capabilities**:
- Parse and understand complex EEG research queries
- Decompose multi-part questions into sub-queries
- Plan optimal agent execution order
- Reason about query complexity and data sources needed
- Adaptive replanning based on intermediate results

**Example Query Plan**:
```
Query: "What EEG biomarkers predict seizure recurrence and which datasets exist for validation?"

CoT Reasoning:
1. Identify two distinct sub-queries:
   a) EEG biomarkers for seizure recurrence
   b) Datasets for validation
2. Determine data sources:
   a) Agent 1 (Local) + Agent 3 (Cloud) for biomarkers
   b) Agent 2 (Web) for datasets
3. Execution Plan:
   - Parallel: Agent 1 + Agent 3 (biomarkers)
   - Sequential: Agent 2 (datasets) after biomarker identification
4. Expected confidence: HIGH (well-researched topic)
```

### Agent 1: Local Data Source Agent
**Role**: Access local vector stores, FAISS indices, and preprocessed EEG corpora

**Data Sources**:
- FAISS vector index (PubMedBERT embeddings)
- Local PubMed corpus (150K+ papers)
- Cached EEG datasets metadata
- Knowledge graph (Neo4j local instance)

**Capabilities**:
- Fast semantic search (<100ms)
- High precision retrieval
- Offline operation
- Citation tracking

**EEG-Specific**:
- Optimized for: ERPs, frequency bands, clinical conditions
- Indexed terms: P300, N400, alpha oscillations, seizure prediction, etc.

### Agent 2: Web Search Engine Agent
**Role**: Real-time web search for latest EEG research and datasets

**Search Engines**:
- PubMed API (live queries)
- Google Scholar
- bioRxiv/medRxiv preprints
- EEG dataset repositories (PhysioNet, OpenNeuro)

**Capabilities**:
- Real-time discovery of new papers
- Dataset availability checking
- Citation count and impact metrics
- Author and institution lookup

**Rate Limits**:
- PubMed: 10 req/s with API key
- Google Scholar: 20 queries/hour (polite scraping)

### Agent 3: Cloud Knowledge Base Agent
**Role**: Access cloud-hosted knowledge bases and APIs

**Cloud Services**:
- **AWS**:
  - Amazon Kendra (enterprise search)
  - S3 (large dataset storage)
  - Neptune (graph database)
- **Azure**:
  - Azure Cognitive Search
  - Azure Blob Storage
  - Cosmos DB (graph)

**Capabilities**:
- Scalable search across massive corpora
- Multi-modal retrieval (text + signals)
- Distributed knowledge graph queries
- High availability (99.9% uptime)

### Agent 4: MCP Server Integration Agent
**Role**: Connect to Model Context Protocol (MCP) servers for specialized resources

**MCP Servers**:
1. **EEG Signal Processing MCP**:
   - Waveform analysis
   - Artifact detection
   - Feature extraction
   
2. **Biomarker Database MCP**:
   - Standardized biomarker definitions
   - Clinical validation studies
   - Normative data

3. **Research Tools MCP**:
   - MATLAB/Python code snippets
   - Analysis pipelines
   - Visualization tools

**Capabilities**:
- Tool use and function calling
- Structured data retrieval
- Code generation for analysis
- Parameter validation

---

## ğŸ”„ Query Processing Flow

### 1. Query Understanding & Planning

```python
# Pseudo-code for Orchestrator
class QueryOrchestrator:
    def plan_query(self, query: str) -> QueryPlan:
        # Step 1: Parse query intent
        intent = self.parse_intent(query)
        
        # Step 2: Chain-of-Thought reasoning
        cot_analysis = self.chain_of_thought_reasoning(query, intent)
        
        # Step 3: ReAct - Reason about actions
        action_plan = self.react_planning(cot_analysis)
        
        # Step 4: Create execution graph
        execution_graph = self.build_execution_graph(action_plan)
        
        return QueryPlan(
            intent=intent,
            reasoning=cot_analysis,
            actions=action_plan,
            execution_graph=execution_graph
        )
```

### 2. Parallel Agent Execution

```python
async def execute_agents(self, plan: QueryPlan) -> List[AgentResult]:
    tasks = []
    
    if plan.requires_local_data:
        tasks.append(self.agent1.search_local(plan.query))
    
    if plan.requires_web_search:
        tasks.append(self.agent2.search_web(plan.query))
    
    if plan.requires_cloud_kb:
        tasks.append(self.agent3.search_cloud(plan.query))
    
    if plan.requires_mcp_tools:
        tasks.append(self.agent4.query_mcp(plan.query))
    
    results = await asyncio.gather(*tasks)
    return results
```

### 3. Context Aggregation

**Short-term Memory** (Working Context):
- Current query results
- Intermediate agent outputs
- Recent conversation history (last 5 turns)

**Long-term Memory** (Persistent Knowledge):
- User preferences and expertise level
- Frequent query patterns
- Validated facts and citations
- Session history

```python
class ContextAggregator:
    def aggregate(self, agent_results: List[AgentResult]) -> EnhancedContext:
        # Deduplicate documents by PMID
        unique_docs = self.deduplicate(agent_results)
        
        # Rank by relevance
        ranked_docs = self.rank_by_relevance(unique_docs)
        
        # Extract key entities (biomarkers, conditions, etc.)
        entities = self.extract_entities(ranked_docs)
        
        # Combine with memory
        context = self.merge_with_memory(ranked_docs, entities)
        
        return EnhancedContext(
            documents=ranked_docs,
            entities=entities,
            short_term_memory=self.short_term,
            long_term_memory=self.long_term
        )
```

### 4. Multi-Model Generation

**Ensemble Strategy**:
- Query GPT-4, Gemini, and Claude in parallel
- Compare responses for consistency
- Use voting or confidence weighting

```python
async def generate_ensemble(self, context: EnhancedContext) -> List[Response]:
    prompt = self.build_prompt(context)
    
    responses = await asyncio.gather(
        self.gpt4.generate(prompt),
        self.gemini.generate(prompt),
        self.claude.generate(prompt)
    )
    
    return responses
```

### 5. Response Aggregation

```python
class AggregatorAgent:
    def synthesize(self, responses: List[Response]) -> FinalResponse:
        # Extract common facts
        common_facts = self.find_consensus(responses)
        
        # Aggregate citations
        all_citations = self.merge_citations(responses)
        
        # Compute confidence
        confidence = self.compute_confidence(responses)
        
        # Generate final text
        final_text = self.synthesize_text(common_facts, confidence)
        
        return FinalResponse(
            text=final_text,
            citations=all_citations,
            confidence=confidence,
            provenance=self.track_sources(responses)
        )
```

---

## ğŸ“š EEG-Specific Components

### EEG Data Sources

1. **PubMed/MEDLINE**:
   - 150K+ EEG papers
   - MeSH terms: "Electroencephalography", "Event-Related Potentials", etc.

2. **PhysioNet**:
   - Sleep-EDF Database
   - CHB-MIT Scalp EEG Database
   - TUH EEG Corpus

3. **OpenNeuro**:
   - EEG datasets with BIDS format
   - Task-based and resting-state

4. **BCI Competition**:
   - Motor imagery datasets
   - P300 speller datasets

### EEG Terminology Database

```python
EEG_TERMINOLOGY = {
    "erp_components": ["P300", "N400", "N170", "P100", "N100", "MMN", "ERN", "Pe"],
    "frequency_bands": ["delta", "theta", "alpha", "beta", "gamma"],
    "clinical_conditions": ["epilepsy", "sleep disorders", "coma", "encephalopathy"],
    "paradigms": ["oddball", "motor imagery", "resting state", "task-based"],
    "biomarkers": ["spike-wave", "sleep spindles", "K-complexes", "alpha asymmetry"],
    "analysis_methods": ["FFT", "wavelet", "ICA", "source localization"]
}
```

### EEG-Specific Libraries

```python
REQUIRED_LIBRARIES = [
    "mne",              # MNE-Python for EEG analysis
    "pyedflib",         # European Data Format reader
    "scipy",            # Signal processing
    "pywavelets",       # Wavelet analysis
    "nilearn",          # Neuroimaging
    "scikit-learn",     # ML algorithms
    "tensorflow",       # Deep learning
    "pytorch",          # Deep learning
    "autoreject",       # Automated artifact rejection
    "fooof",            # Parameterizing neural power spectra
]
```

---

## ğŸ”’ Security & Privacy

- API keys stored in environment variables
- No PHI (Protected Health Information) in training data
- Rate limiting on all external APIs
- Audit logging for all agent actions
- Data encryption at rest and in transit

---

## ğŸ“Š Performance Targets

| Metric | Target | Notes |
|--------|--------|-------|
| Query Planning Time | < 500ms | Orchestrator CoT reasoning |
| Agent Execution (parallel) | < 2s | All agents combined |
| Context Aggregation | < 300ms | Dedup + ranking |
| Generation (single model) | < 3s | GPT-4/Gemini/Claude |
| Total Latency (p95) | < 8s | End-to-end with caching |
| Cache Hit Rate | > 40% | For popular queries |

---

## ğŸš€ Implementation Phases

### Phase 1: Core Orchestrator (Week 1-2)
- [ ] Query understanding and intent classification
- [ ] CoT reasoning engine
- [ ] ReAct planning logic
- [ ] Execution graph builder

### Phase 2: Agent Implementation (Week 3-5)
- [ ] Agent 1: Local data source integration
- [ ] Agent 2: Web search implementation
- [ ] Agent 3: Cloud KB connectors
- [ ] Agent 4: MCP server client

### Phase 3: Memory Systems (Week 6-7)
- [ ] Short-term memory (Redis)
- [ ] Long-term memory (SQLite/PostgreSQL)
- [ ] Memory retrieval and fusion

### Phase 4: Generation Ensemble (Week 8-9)
- [ ] Multi-model integration
- [ ] Response comparison logic
- [ ] Aggregator agent implementation

### Phase 5: Testing & Optimization (Week 10-12)
- [ ] End-to-end testing
- [ ] Performance optimization
- [ ] EEG-specific validation

---

## ğŸ“ Example Query Flows

### Example 1: Simple Factual Query

**Query**: "What is the typical P300 latency?"

**Plan**:
1. Intent: Factual retrieval
2. Agents: Agent 1 (Local) only - high confidence for well-known fact
3. Generation: Single model (GPT-3.5) sufficient
4. Expected latency: <1.5s

### Example 2: Complex Multi-Part Query

**Query**: "Compare deep learning vs traditional methods for seizure detection and list available datasets"

**Plan**:
1. Intent: Comparison + dataset discovery
2. Sub-queries:
   - "Deep learning for seizure detection"
   - "Traditional methods for seizure detection"
   - "Seizure detection datasets"
3. Agents:
   - Agent 1 (Local): Literature comparison
   - Agent 2 (Web): Latest papers + datasets
   - Agent 3 (Cloud): Large-scale comparison studies
4. Generation: Ensemble (all 3 models) for comprehensive answer
5. Expected latency: <8s

### Example 3: Code Generation Query

**Query**: "Show me Python code to detect alpha oscillations using MNE"

**Plan**:
1. Intent: Code generation
2. Agents:
   - Agent 4 (MCP): Code snippet repository
   - Agent 2 (Web): GitHub examples
3. Generation: Claude (best for code)
4. Expected latency: <4s

---

**Next Steps**: Implement orchestrator and agent base classes
